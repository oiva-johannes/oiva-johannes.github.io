<article>
    <h2>What Makes Dialogue With LLM Worth It?</h2>
    <br>
    <time>08.09.2024 English</time>
    <br><br><br>
    <h3>Sunday afternoons</h3>
    <p class="post-p">
        In many sunday afternoons when I'm relaxed and peaceful at home, my thoughts flow freely and I need to validate some of those ideas pushing through.
        Maybe the silence and the peacefulness of the afternoon sunbeams shining through my window causes this.
        In these moments I've started to notice having conversations with Claude 3.5 when wanting to validate someone of those ideas (and fast).
        For those that don't know, Claude is large language model (LLM) developed by Anthropic.
        At first (and still) it felt like a slippery slope to do this because current LLMs, like Claude, are far from perfect.
        They make mistakes and give shallow answers on a regular basis. 
        This makes sense since LLMs are the generalization of their underlying distribution (that they have been trained on).
        But in the end of the day does any of that even matter?
        In some ways those things also apply to humans; as humans also make mistakes and are the generalization of their surrounding environment on which they grew up on.
    </p>
    <h3>Positive reinforcement</h3>
    <p class="post-p">
        In my mind the objections against LLMs don't matter as long as the conversations are fruitful and help me to grow and reinforce my ideas.
        At first I was sceptical of this, but I've really noticed that some of the conversations I've had have been excellent for exploring my ideas and for improving my thinking on a subject.
        Obviously the most important thing in these conversations is that I get feedback for my ideas. 
        But the quality of the feedback is also important.
        The feedback needs to be thought provoking; so that it seeds new subideas from the original idea.
        And then you can talk about these new subideas and do the cycle again and again; making it a positive reinforcement loop for new different ideas.
        And having those different ideas interconnect to each other and understanding the connections they share.
        These are some of the important aspects for fruitful conversations.
        But the most important aspect of the feedback is the objectivity.
        You want the model to <b>pushback</b> on your ideas and suggestions. 
        You want the model to be as objective as possible while still positively reinforcing and motivating you to explore more ideas.
        This is because nobody wants to have a conversation with a yes-man.
        A yes-man never truly engages or provokes you.
        A yes-man will only tell you what you want to hear; and that never brings anything new to the table.
        So some type of <b>middle ground</b> between reinforcement and pushback would be the perfect feedback to get.
        But as I said before, these models aren't perfect so the reality can be quite different at times.
        Still these models have came far enough so the utility in some capacity is there.
    </p>
    <h3>Pick the right use case</h3>
    <p class="post-p">
        Important part of the skill of using LLMs is to be able to know when they can be useful and when they can't.
        So when using LLMs you have to understand the right and wrong use cases for them.
        My advice based on anecdotal evidence is this: no domain spesific conversations or questions, because that is often where LLM crumbles the worst.
        So for example, trying to discuss math on detailed level is bad idea and probably wastes more of your time then you just reading an actual textbook (textbooks are important!).
        More overarching, general and diverse conversations are better suited to be had with an LLM; especially those that contain semantics.
        So talk about big picture ideas and concepts!
        NOT implementation details or spesifications.
        In some ways LLMs are the <b>idea machines</b> of our time. 
        And our job is to validate which of those ideas are actually good and which can be realistically implemented.
        Watch this REALLY GOOD machine learning street talk episode related to this notion:
    </p>
    <iframe width="300" src="https://www.youtube-nocookie.com/embed/y1WnHpedi2A?si=Oir9Gr4wpeDFVAgD" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

</article>